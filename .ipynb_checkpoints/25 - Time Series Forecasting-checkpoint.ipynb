{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JCLYcTRUtmtu"
   },
   "source": [
    "# Time Series Forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "avYz9tu3JluG"
   },
   "outputs": [],
   "source": [
    "## update the latest seaborn (0.9.0)\n",
    "!pip install seaborn==0.9.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Q5E02b2TUz0y"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting prophet\n",
      "  Downloading https://files.pythonhosted.org/packages/1b/1c/61c969e76119a8257220869a6b3b57cd2ad4fbe0fd69b9b6845bfcf135aa/prophet-0.1.1.tar.gz\n",
      "Requirement already satisfied: pytz>=2014.9 in /anaconda3/lib/python3.6/site-packages (from prophet) (2018.4)\n",
      "Requirement already satisfied: pandas>=0.15.1 in /anaconda3/lib/python3.6/site-packages (from prophet) (0.23.0)\n",
      "Requirement already satisfied: six>=1.8.0 in /anaconda3/lib/python3.6/site-packages (from prophet) (1.11.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.0 in /anaconda3/lib/python3.6/site-packages (from pandas>=0.15.1->prophet) (2.7.3)\n",
      "Requirement already satisfied: numpy>=1.9.0 in /anaconda3/lib/python3.6/site-packages (from pandas>=0.15.1->prophet) (1.14.3)\n",
      "Building wheels for collected packages: prophet\n",
      "  Running setup.py bdist_wheel for prophet ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /Users/Kyle_Staples/Library/Caches/pip/wheels/77/3e/f3/1c536bf1f871f818686e7fbf31cab18d52787a72dea8640756\n",
      "Successfully built prophet\n",
      "Installing collected packages: prophet\n",
      "Successfully installed prophet-0.1.1\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 19.0.3 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "## install a tool, prophet\n",
    "!pip install prophet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "u2NphvDnZRrV"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'fbprophet'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-1ba98fafcb54>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mfbprophet\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mProphet\u001b[0m \u001b[0;31m## <----- new import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'fbprophet'"
     ]
    }
   ],
   "source": [
    "## setup our environment\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime  \n",
    "from fbprophet import Prophet ## <----- new import\n",
    "\n",
    "\n",
    "## pandas print columns/rows option (100)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "## set the styling for seaborn (white)\n",
    "sns.set_style(\"dark\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eGkYvKDKG4Ft"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File b'sales.csv' does not exist: b'sales.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-8e97c87ce90d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# lets use the sales dataset again\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msales\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"sales.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparse_dates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Order Date'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Ship Date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0msales\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/Python_37/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    700\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    703\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/Python_37/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 429\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/Python_37/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/Python_37/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1120\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1121\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1122\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1123\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1124\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/Python_37/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1851\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'usecols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1852\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1853\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1854\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1855\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File b'sales.csv' does not exist: b'sales.csv'"
     ]
    }
   ],
   "source": [
    "# lets use the sales dataset again\n",
    "sales = pd.read_csv(\"sales.csv\", parse_dates=['Order Date', 'Ship Date'])\n",
    "sales.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PFGwl-JtHNjo"
   },
   "outputs": [],
   "source": [
    "# lets summarize sales by order date again\n",
    "sales_ts = sales.groupby(\"Order Date\", as_index=False).sum()\n",
    "sales_ts = sales_ts.loc[:, [\"Order Date\", \"Sales\"]]\n",
    "sales_ts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kq8tQO4JHlck"
   },
   "outputs": [],
   "source": [
    "# quick plot\n",
    "sales_ts.plot(x=\"Order Date\", y=\"Sales\", kind=\"line\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "csbMsyKqH1t7"
   },
   "source": [
    "> Because we are interested in forecasting values, we want to use historical data to predict future values.  As with any type of prediction problem, we need to setup some method to assess accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ch__PBobHo-b"
   },
   "source": [
    "# Evaluation and Moving Average (MA) forecasting\n",
    "\n",
    "There are a number of ways to evaluate timeseries forecasts, but to keep things within context of this course, let's use a simple** RMSE, or Root Mean Squared Error**\n",
    "\n",
    "This simply is the different between the forecasts and the actual value (a residual), squared, and then take the square root.  We do this for every forecast in our dataset to arrive at 1 number.  The lower the **RMSE**, the better, just like in regression.\n",
    "\n",
    "An intuitive, and often great first step, is to forecast via moving averages.  Simply, the moving average over some period (e.g. MA(4) is a 4-period moving average) is used to forecast the value.  It is a smoothing type of forecast, as the data are pooled together via an average in attempts to remove larger fluctations.  The accuracy of a MA forecast tends to be in the window selected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8tlZ0oC4IYf_"
   },
   "outputs": [],
   "source": [
    "# first, lets add a few moving averages\n",
    "sales_ts['ma1'] = sales_ts['Sales'].shift().rolling(1).mean()\n",
    "sales_ts['ma2'] = sales_ts['Sales'].shift().rolling(2).mean()\n",
    "sales_ts['ma5'] = sales_ts['Sales'].shift().rolling(5).mean()\n",
    "sales_ts['ma12'] = sales_ts['Sales'].shift().rolling(12).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EtKMnn3OI3tk"
   },
   "outputs": [],
   "source": [
    "sales_ts.head(13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AUOqJE3sI5Cd"
   },
   "outputs": [],
   "source": [
    "# Now we calculate the RMSE for each prediction.  First we square the error/residual\n",
    "# That is Sales is what we want to predict, and the MA(n) is the forecast for that value\n",
    "sales_ts['ma1_se'] = (sales_ts['Sales'] - sales_ts['ma1'])**2\n",
    "sales_ts['ma2_se'] = (sales_ts['Sales'] - sales_ts['ma2'])**2\n",
    "sales_ts['ma5_se'] = (sales_ts['Sales'] - sales_ts['ma5'])**2\n",
    "sales_ts['ma12_se'] = (sales_ts['Sales'] - sales_ts['ma12'])**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "u6QMZhaJJ9Hd"
   },
   "outputs": [],
   "source": [
    "# lets look at the data\n",
    "sales_ts.head(13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X3RAMxm0KMwK"
   },
   "outputs": [],
   "source": [
    "# lets only keep rows where every value is retained, this only chops off a few records and doesnt really matter in practice\n",
    "sales_forecast = sales_ts.dropna()\n",
    "print(len(sales_ts))\n",
    "print(len(sales_forecast))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GY-i1s0kKdbL"
   },
   "outputs": [],
   "source": [
    "# keep just what we need\n",
    "evals = sales_forecast.iloc[:, 6:]\n",
    "evals.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xWU2QX0eLnZh"
   },
   "outputs": [],
   "source": [
    "## calculate the averages\n",
    "evals_mean = evals.mean()\n",
    "evals_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6j5dVgyKMCPR"
   },
   "outputs": [],
   "source": [
    "## take our Series and make it a dataframe, \n",
    "evals_df = pd.DataFrame({'mse': evals_mean})\n",
    "evals_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fr_KDjK1MDWw"
   },
   "outputs": [],
   "source": [
    "# now square root of the number\n",
    "evals_df['rmse'] = np.sqrt(evals_df['mse'])\n",
    "evals_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cr26SB33McBp"
   },
   "outputs": [],
   "source": [
    "# create a barplot showing a picture\n",
    "evals_df['method'] = evals_df.index\n",
    "evals_df.rmse.plot(kind=\"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2ylJ3FeQNAnx"
   },
   "outputs": [],
   "source": [
    "# visualize the forecasts - last 50\n",
    "proof = sales_forecast.iloc[:, :6]\n",
    "proof50 = proof.tail(50)\n",
    "proof_eval = proof50.melt(id_vars=\"Order Date\", var_name=\"method\")\n",
    "# fig, ax = plt.subplots(figsize=(10,4))  ## <---- this lets us access the figure and axes objects for finer control, using it to set the axis method\n",
    "# fig = sns.lineplot(x=\"Order Date\", y=\"value\", data=proof_eval, hue=\"method\")\n",
    "# plt.show(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2bdJKxP7ZL3h"
   },
   "source": [
    "# Prophet\n",
    "\n",
    "![](https://cdn-images-1.medium.com/max/1600/0*tVCene42rgUTNv9Q.png)\n",
    "\n",
    "Facebook built prophet to do robust, scalable, yet simple timeseries forecasting.  For our purposes, this can help us go a long way.\n",
    "\n",
    "To learn more about prophet:\n",
    "\n",
    "https://facebook.github.io/prophet/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aI5K5niWZ1nl"
   },
   "outputs": [],
   "source": [
    "# load the shampoo dataset from QTools with some basic cleanup\n",
    "shampoo = pd.read_csv(\"shampoo.csv\")\n",
    "shampoo.dropna(inplace=True)\n",
    "shampoo.columns = ['Month', 'Sales']\n",
    "shampoo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YavK1nM0aMzY"
   },
   "outputs": [],
   "source": [
    "# lets create a date and remove month\n",
    "shampoo['date'] = pd.date_range(start=\"2019-01-01\", periods=36)\n",
    "del shampoo['Month']\n",
    "# reorder the columns\n",
    "shampoo = shampoo.loc[:, [\"date\", \"Sales\"]]\n",
    "shampoo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9VtbByMDaUfB"
   },
   "outputs": [],
   "source": [
    "shampoo.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RQPTsw5fazgZ"
   },
   "outputs": [],
   "source": [
    "# Prophet requires a dataframe with two coluns, ds and y, for the dates and values respectively\n",
    "shampoo.columns = [\"ds\", \"y\"]\n",
    "shampoo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2-DonrKyagwE"
   },
   "outputs": [],
   "source": [
    "# create a model using prophet\n",
    "model = Prophet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Pmf5J6bmaoV8"
   },
   "outputs": [],
   "source": [
    "# fit a model to our data - it might takea a few seconds\n",
    "model.fit(shampoo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ROULVef2auN8"
   },
   "source": [
    "> Above is just telling us that some of the settings were disabled, but if we want to include settings that account for daily and yearly seasonility, we can.\n",
    "\n",
    "Prophet fit a model to our data, and has a nice helper function to extend our shampoo sales data into the future (add new dates) and use the model to forecast those values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VqmVUQkobIzh"
   },
   "outputs": [],
   "source": [
    "# add 3 days to the shampoo dataset and get it ready to apply the forecasts\n",
    "future = model.make_future_dataframe(periods=3, freq='D', include_history=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "q1RVf1RJbpec"
   },
   "outputs": [],
   "source": [
    "# add the forecasts to the dataset\n",
    "shampoo_forecasts = model.predict(future)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-_ZtTt5RbySu"
   },
   "outputs": [],
   "source": [
    "# look at the tail of the dataset\n",
    "shampoo_forecasts.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "x9kyN3Q2cM8q"
   },
   "outputs": [],
   "source": [
    "# thats a lot of data on how prophet worked through the dataset to decompose various components of the dataset for forecasting\n",
    "# we can plot the forecast\n",
    "fig1 = model.plot(shampoo_forecasts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aLgvYXzBceui"
   },
   "source": [
    "Above shows us a plot of the forecast, along with the confidence of the estimate, which allows us to view the \"risk\" of our predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NrPlWBHudvj0"
   },
   "outputs": [],
   "source": [
    "## we can also join this back to our original dataset\n",
    "## outer join to include all data, because we added dates with prophet\n",
    "shampoo_final = pd.merge(shampoo, shampoo_forecasts, how=\"outer\", left_on=[\"ds\"], right_on=[\"ds\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TUIO7dd8eE34"
   },
   "outputs": [],
   "source": [
    "# inspect the data - notice the last 3 do not have the original value, y, as expected\n",
    "shampoo_final.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wdFVEl1zj0ZA"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RZ3L6yglj4vo"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "25 - Time Series Forecasting.ipynb",
   "private_outputs": true,
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
