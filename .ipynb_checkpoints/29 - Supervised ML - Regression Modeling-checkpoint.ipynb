{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UaekvSbt9p0o"
   },
   "source": [
    "# Supervised Machine Learning - Regression and Decision Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "l8bM7JzX90__"
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "avYz9tu3JluG"
   },
   "outputs": [],
   "source": [
    "## update the latest seaborn (0.9.0)\n",
    "!pip install seaborn==0.9.0\n",
    "!pip install prophet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "u2NphvDnZRrV"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'graphviz'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-9d01b470d96f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDecisionTreeRegressor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mgraphviz\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'graphviz'"
     ]
    }
   ],
   "source": [
    "## setup our environment\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "## date and timeseries forecasting tooling\n",
    "import datetime\n",
    "from fbprophet import Prophet\n",
    "\n",
    "## machine learning/predictive analytics tools             \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier           # <-------- New imports start here!\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LinearRegression \n",
    "from sklearn.tree import DecisionTreeRegressor \n",
    "from sklearn import metrics\n",
    "import graphviz \n",
    "from sklearn import tree\n",
    "\n",
    "\n",
    "## pandas print columns/rows option (100)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "## set the styling for seaborn (white)\n",
    "sns.set_style(\"dark\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Yry_mI4H960H"
   },
   "source": [
    "# The Dataset\n",
    "\n",
    "We will stick with the California Homes Dataset built into Collab, but is also included on Q-Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-9kqFyy3isd9"
   },
   "outputs": [],
   "source": [
    "# bring in the dataset\n",
    "homes = pd.read_csv(\"/Users/Kyle_Staples/Documents/GitHub/IS834/datasets/california_housing_train.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oFwqsFXtmPUq"
   },
   "outputs": [],
   "source": [
    "homes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L6lXIOuNiwC0"
   },
   "outputs": [],
   "source": [
    "homes.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z08xM_JN_gaT"
   },
   "outputs": [],
   "source": [
    "# quick plot to look at the distribution\n",
    "sns.distplot(a=homes['median_house_value'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7_c56Z-S-R1c"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qeRpseYMizEW"
   },
   "source": [
    "# LInear Regression vs Logistic Regression\n",
    "\n",
    "<h3> We are moving away from Classifiers and looking at Regression Techniques </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "z2jQ_k76-TiQ"
   },
   "source": [
    "![](data:image/png;base64,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)\n",
    "\n",
    "When we want to predict a target variable (y) that is continous and hopefully fits a nice distribution, and one that is not skewed too badly.  \n",
    "  \n",
    "\n",
    "For example:\n",
    "\n",
    "- how many days until the customer purchases from us again\n",
    "- sales for a given marketing campaign\n",
    "- home valuations\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QwiJI36GgL-r"
   },
   "outputs": [],
   "source": [
    "# lets look at the distribution plot again\n",
    "sns.distplot(a=homes['median_house_value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AoVj0jTQgQTh"
   },
   "outputs": [],
   "source": [
    "# somethign is going on with the coding, given a major spike at the tail\n",
    "homes.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LBIQlq0agT2d"
   },
   "outputs": [],
   "source": [
    "# it looks like there is a catchall, 500001 for any value above 500000\n",
    "# lets cut the tail off to remove the coding scheme from impacting our results\n",
    "homes_clean = homes.loc[homes['median_house_value'] < 500000, ]\n",
    "homes_clean.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VoJzGi4vgl2L"
   },
   "outputs": [],
   "source": [
    "# now the displot again\n",
    "sns.distplot(a=homes_clean['median_house_value'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "m6L2pZPmgsgG"
   },
   "source": [
    "# OLS Linear Regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XcOX8xGHhXsG"
   },
   "outputs": [],
   "source": [
    "# just like the other techniques, we have to split our data\n",
    "# but for OLS, lat/long are not proper since they are geo-baesd and the model will look for unit changes\n",
    "y = homes_clean.median_house_value\n",
    "X = homes_clean.drop(columns=[\"median_house_value\", \"longitude\", \"latitude\"], inplace=False)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,  test_size = .25, random_state=33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eqRhWkUMh_-0"
   },
   "outputs": [],
   "source": [
    "# instantiate the model\n",
    "reg_ols = LinearRegression()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kp6bIeeaiQp_"
   },
   "outputs": [],
   "source": [
    "# fit the model with the test set\n",
    "reg_ols.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sKVgFnMTiUzx"
   },
   "outputs": [],
   "source": [
    "# make predictions on the test set\n",
    "reg_ols_preds = reg_ols.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bOm901c1i1FR"
   },
   "outputs": [],
   "source": [
    "reg_ols_preds[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EJWjx4CFifpx"
   },
   "outputs": [],
   "source": [
    "# lets put the predictions and the actual values for y test together and look at the scatterplot\n",
    "reg_ols_df = pd.DataFrame({'y':y_test, 'yhat':reg_ols_preds}, )\n",
    "reg_ols_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PHWr9Lwki7FI"
   },
   "outputs": [],
   "source": [
    "# the plot\n",
    "sns.lmplot(x=\"yhat\", y=\"y\", data=reg_ols_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ftjlaSgmjYW4"
   },
   "source": [
    "> What do we thnk about above?  \n",
    "\n",
    "Takaways:\n",
    "\n",
    "*  Observation 1\n",
    "- Observation 2\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2dC0ggaMjq6e"
   },
   "outputs": [],
   "source": [
    "# we get the model r2\n",
    "reg_ols_r2 = metrics.r2_score(y_test, reg_ols_preds)\n",
    "reg_ols_r2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vbsDeycflMvd"
   },
   "source": [
    "The multiple regression equation\n",
    "\n",
    "![](http://aalb.co.in/wp-content/uploads/2018/02/multi-regression-equation.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-Ncc6AjckO1i"
   },
   "outputs": [],
   "source": [
    "# the coeffecients of the model\n",
    "print(X_train.columns)\n",
    "print(reg_ols.intercept_)\n",
    "print(reg_ols.coef_)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EixPdjUCk6fO"
   },
   "source": [
    "## Exercise:\n",
    "\n",
    "Write out the equation of the model given the output we are finding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "X0u6NjJKkwlj"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "u9apeZA4l-r6"
   },
   "source": [
    "# Regression Tree\n",
    "\n",
    "Just like used a Decision Tree to classify homes on their value relative to the average (yes or no), we can also use the same concept,but for regression tasks.  Prior, those were referred to as a Classification Tree.  When we perform regressions, these are referred to as Regression Trees.  Moving forward, Decision Trees can do Classification or Regression, and sometimes we will refer to the technique as Classification and Regression Trees, instead of Decision Trees.    It's all the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AZTjirbhmezJ"
   },
   "outputs": [],
   "source": [
    "# we will use the same data above - but instantitate the Regression tree\n",
    "# just like I did in the exercise, I am telling scikit learn that I only want a tree of depth 5 and each split needs at least 15 rows of data\n",
    "reg_tree = DecisionTreeRegressor(max_depth=5, min_samples_split=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DF7x0_tNmvAy"
   },
   "outputs": [],
   "source": [
    "# fit the model with the test set\n",
    "reg_tree.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Xsl_DHyXmyi2"
   },
   "outputs": [],
   "source": [
    "# make the predictions for on the test set\n",
    "reg_tree_preds = reg_tree.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "F9yv-JrtnBnX"
   },
   "outputs": [],
   "source": [
    "# create the dataframe for putting the data back together\n",
    "reg_tree_df = pd.DataFrame({'y':y_test, 'yhat':reg_tree_preds}, )\n",
    "reg_tree_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8phYL-jwnYFc"
   },
   "outputs": [],
   "source": [
    "# lets look at the fit as we did for the OLS method\n",
    "sns.lmplot(x=\"yhat\", y=\"y\", data=reg_tree_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "w21NZow-nciC"
   },
   "source": [
    "> Why do we think the picture looks different?  \n",
    "\n",
    "- Reason 1\n",
    "- Reason 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZMZUmCt1nv9I"
   },
   "source": [
    "<img src=\"https://monosnap.com/image/VcRwBMnry38K56YPCBCd3rwiD98dIk.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_Nin_FIHnxJo"
   },
   "outputs": [],
   "source": [
    "# The r2 for the tree\n",
    "reg_tree_r2 = metrics.r2_score(y_test, reg_tree_preds)\n",
    "reg_tree_r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Pxl1Y50dosoX"
   },
   "outputs": [],
   "source": [
    "# generate the plot for the tree\n",
    "dot_data = tree.export_graphviz(reg_tree, \n",
    "                                out_file=None, \n",
    "                                feature_names=X.columns,\n",
    "                                filled=True,\n",
    "                                rounded=True)\n",
    "graph = graphviz.Source(dot_data) \n",
    "graph.render(\"Regression Tree - CA Home Value\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-QVy8Y4OqUvf"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sTjYTLJNo_jJ"
   },
   "source": [
    "## Data munging Example/Exercise\n",
    "\n",
    "If we wanted to plot both predictions against the actual values, we can, but we need to put the parts together.\n",
    "\n",
    "We will stack the dataframes (one on top of the other) and create a column to flag which model is being used.  This new column will be what we use to segment the model data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EchR7ZAhqT-c"
   },
   "outputs": [],
   "source": [
    "# first, add the model type to each of the two dataframes\n",
    "reg_ols_df['model'] = \"ols\"\n",
    "reg_tree_df['model'] = \"tree\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nnZd-yC2qgQq"
   },
   "outputs": [],
   "source": [
    "# stack, or concat, the datasets\n",
    "reg_models = pd.concat([reg_ols_df, reg_tree_df])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "11jYLraHqoZK"
   },
   "outputs": [],
   "source": [
    "# confirm that worked\n",
    "reg_models.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R27X_7J5qqy-"
   },
   "outputs": [],
   "source": [
    "reg_models.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qkbf52PuquGR"
   },
   "outputs": [],
   "source": [
    "# the plot\n",
    "sns.lmplot(x=\"yhat\", y=\"y\", data=reg_models, hue=\"model\", height=7, scatter_kws={'alpha':.2})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZxiwHsS7q0Ts"
   },
   "outputs": [],
   "source": [
    "# compare the two models\n",
    "print(\"ols r2 = \" + str(reg_ols_r2))\n",
    "print(\"tree r2 = \" + str(reg_tree_r2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ia2YfHItsrO4"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Q1sEEWrdrLUl"
   },
   "source": [
    "# Regression Exercise\n",
    "\n",
    "Predict the price of diamonds using the following dataset:\n",
    "\n",
    "`https://vincentarelbundock.github.io/Rdatasets/csv/ggplot2/diamonds.csv`\n",
    "\n",
    "- Fit an OLS regression and Regression Tree\n",
    "- You are predicting the variable `price`\n",
    "\n",
    "For documentation on the dataset:\n",
    "\n",
    "https://vincentarelbundock.github.io/Rdatasets/doc/ggplot2/diamonds.html\n",
    "\n",
    "In this exercise:\n",
    "\n",
    "1. Review the columns, you will need to make decisions which to keep\n",
    "1. Fit both an OLS and Decision Tree Regression Model\n",
    "1. Create a scatter plot showing the actual and predicted values\n",
    "1. Which performs better based on R2?\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "j8Q_n5a8sqVD"
   },
   "outputs": [],
   "source": [
    "# import the dataset\n",
    "diamonds = "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "29 - Supervised ML - Regression Modeling.ipynb",
   "private_outputs": true,
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
