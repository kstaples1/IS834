{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UaekvSbt9p0o"
   },
   "source": [
    "# Supervised Machine Learning - Regression and Decision Trees\n",
    "\n",
    "REMINDER:  No Class Next week, next is the 24th\n",
    "\n",
    "                       Assignment will be due at the start of that class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "l8bM7JzX90__"
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "avYz9tu3JluG"
   },
   "outputs": [],
   "source": [
    "## update the latest seaborn (0.9.0)\n",
    "!pip install seaborn==0.9.0\n",
    "!pip install prophet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "u2NphvDnZRrV"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'graphviz'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-fc0a231284d9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear_model\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLinearRegression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mgraphviz\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'graphviz'"
     ]
    }
   ],
   "source": [
    "## setup our environment\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "## date and timeseries forecasting tooling\n",
    "import datetime\n",
    "from fbprophet import Prophet\n",
    "\n",
    "## machine learning/predictive analytics tools             \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier           # <-------- New imports start here!\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LinearRegression \n",
    "from sklearn import metrics\n",
    "import graphviz \n",
    "from sklearn import tree\n",
    "\n",
    "\n",
    "## pandas print columns/rows option (100)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "## set the styling for seaborn (white)\n",
    "sns.set_style(\"dark\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Yry_mI4H960H"
   },
   "source": [
    "# The Dataset\n",
    "\n",
    "https://www.kaggle.com/ronitf/heart-disease-uci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-9kqFyy3isd9"
   },
   "outputs": [],
   "source": [
    "# bring in the dataset\n",
    "heart = pd.read_csv(\"/Users/Kyle_Staples/Documents/GitHub/IS834/datasets/heart-1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oFwqsFXtmPUq"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 303 entries, 0 to 302\n",
      "Data columns (total 14 columns):\n",
      "age         303 non-null int64\n",
      "sex         303 non-null int64\n",
      "cp          303 non-null int64\n",
      "trestbps    303 non-null int64\n",
      "chol        303 non-null int64\n",
      "fbs         303 non-null int64\n",
      "restecg     303 non-null int64\n",
      "thalach     303 non-null int64\n",
      "exang       303 non-null int64\n",
      "oldpeak     303 non-null float64\n",
      "slope       303 non-null int64\n",
      "ca          303 non-null int64\n",
      "thal        303 non-null int64\n",
      "target      303 non-null int64\n",
      "dtypes: float64(1), int64(13)\n",
      "memory usage: 33.2 KB\n"
     ]
    }
   ],
   "source": [
    "heart.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L6lXIOuNiwC0"
   },
   "outputs": [],
   "source": [
    "heart.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z08xM_JN_gaT"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a139f82b0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# quick countplut of the target variable counts\n",
    "sns.countplot(x=\"target\", data=heart)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7_c56Z-S-R1c"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qeRpseYMizEW"
   },
   "source": [
    "# Logistic Regression \n",
    "\n",
    "<h3> Another Classification Method </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "z2jQ_k76-TiQ"
   },
   "source": [
    "![](http://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1534281070/linear_vs_logistic_regression_edxw03.png)\n",
    "\n",
    "When we want to classify a target variable (y) that has 2 categories.  Even though the target is numeric and almost always 0 / 1, a linear regression will not fit the data well.\n",
    "\n",
    "Instead, we use a logistic regression, and the code of __1__ represents the target category of interest.  \n",
    "\n",
    "For example:\n",
    "\n",
    "- did the customer default on their bank loan\n",
    "- did the actor win the award\n",
    "- does a patient have an illness\n",
    "- does a customer return next year\n",
    "- does a stock go up in price tomorrow?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gfGKnFOqlF8v"
   },
   "outputs": [],
   "source": [
    "# instantiate the model\n",
    "logreg = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qO61VX8hlO6r"
   },
   "outputs": [],
   "source": [
    "# break out the dataset into X (features) and y (target)\n",
    "X = heart.drop(columns=[\"target\"])\n",
    "y = heart.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bu2ky5rF_Wqu"
   },
   "source": [
    "![](https://d2h0cx97tjks2p.cloudfront.net/blogs/wp-content/uploads/sites/2/2018/08/1-16.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TGwnM6rfl10S"
   },
   "outputs": [],
   "source": [
    "# train test splits\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,  test_size = .25, random_state=33, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XKecL-uAlxMG"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the model\n",
    "logreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zBqbMKRxmWzp"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8289473684210527"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what is the simple accuracy score: we use test dataset\n",
    "logreg.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y3XchXlhmr6s"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5445544554455446"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what was the baseline percentage\n",
    "y.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hboXATl8_Ea1"
   },
   "source": [
    "> Did we improve our ability to gain insight from the dataset?  If so, why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "w4f2CpzGnNyG"
   },
   "outputs": [],
   "source": [
    "# generate the prdections\n",
    "logreg_preds = logreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3qWB9TEMmv-3"
   },
   "outputs": [],
   "source": [
    "# confusion matrix -- what we knew to be true, and what we predicted for the test set\n",
    "cmatrix = metrics.confusion_matrix(y_test, logreg_preds)\n",
    "cmatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6Tnq2PAhnJP6"
   },
   "outputs": [],
   "source": [
    "# plot\n",
    "fig = sns.heatmap(cmatrix, annot=True, cmap=\"Blues\")\n",
    "fig.set(xlabel='Predicted', ylabel='Actual')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jkF4fwYt7TWA"
   },
   "outputs": [],
   "source": [
    "# classififcation report -- support is number of records/occurrences\n",
    "print(metrics.classification_report(y_test, logreg_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "q72_EbuwNXT5"
   },
   "outputs": [],
   "source": [
    "# calculate the estiamted probabilities for the target class = 1, which is the s\n",
    "logreg_y_probs = logreg.predict_proba(X_test)\n",
    "logreg_y_probs[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VPoGtQG9Wx43"
   },
   "outputs": [],
   "source": [
    "# from above, we have two columns, and they align to the target values, 0, then 1,\n",
    "# so we want the second column\n",
    "logreg_y_probs = logreg_y_probs[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GRUHuFy_9m0K"
   },
   "outputs": [],
   "source": [
    "# calulate the ROC curve and include AUC within the plot\n",
    "auc_logreg = metrics.roc_auc_score(y_test, logreg_y_probs)\n",
    "auc_logreg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "48VkwcS87ALt"
   },
   "source": [
    "<img src=\"https://monosnap.com/image/YSv8XTNdP1U4kt5mOgVnjpSPqwjL1e.png\">\n",
    "\n",
    "Source = http://gim.unmc.edu/dxtests/roc3.htm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "53xjc6UzFw0s"
   },
   "outputs": [],
   "source": [
    "# last but not least, look at the model -- its possible to get better output with statsmodels, but Id rather us fit some models and explore accuracy right now\n",
    "print(X.columns)\n",
    "logreg.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "H0_Z64aGGwLF"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hkdAIcZTEb0L"
   },
   "source": [
    "## Logistic Regression Exercise\n",
    "\n",
    "Using the sample dataset found here in Collab, fit a logistic regression to predict the value of the target variable.  \n",
    "\n",
    "You should:\n",
    "\n",
    "- Consider if the variables are appropriate to be included in the model\n",
    "- calculate the accuracy and AUC of the model\n",
    "- determine if the model performed better than guessing (the baseline)\n",
    "\n",
    "\n",
    "Hint:\n",
    "\n",
    "> The target variable is dervied directly from the median_house_value column and will inflate your results if included"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1O8rRexNEiwl"
   },
   "outputs": [],
   "source": [
    "# load the data\n",
    "house = pd.read_csv(\"sample_data/california_housing_train.csv\")\n",
    "house['target'] = (house['median_house_value'] >  house['median_house_value'].mean()).astype(\"int\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cPbbKRtPJikV"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "k-s3sg02FR8A"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "v9MS3a26CheB"
   },
   "source": [
    "# Decision Trees\n",
    "\n",
    "<img src=\"https://monosnap.com/image/77aOgM9OjPnPRPzg0e8F7OKsAdh41m.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PXokeovXDMpE"
   },
   "outputs": [],
   "source": [
    "# instantiate the model\n",
    "dtree = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sVeSvY9mKbsf"
   },
   "outputs": [],
   "source": [
    "# fit the model to the data we have already split\n",
    "dtree.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lIQhaF1qKfnr"
   },
   "outputs": [],
   "source": [
    "# evaluate the accuracy of the model\n",
    "dtree.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9UmaLGARND89"
   },
   "outputs": [],
   "source": [
    "# calculate predictions\n",
    "dtree_preds = dtree.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lsj_8sKkMB1I"
   },
   "outputs": [],
   "source": [
    "# classififcation report -- support is number of records/occurrences\n",
    "print(metrics.classification_report(y_test, dtree_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4ICvEstqNKUj"
   },
   "outputs": [],
   "source": [
    "# calculate the probabilities for the target class of 1, the second column\n",
    "dtree_y_probs = dtree.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xs822zjxO0sq"
   },
   "outputs": [],
   "source": [
    "# calculate the auc\n",
    "auc_tree = metrics.roc_auc_score(y_test, dtree_y_probs)\n",
    "auc_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "38jP9VQ4O9pM"
   },
   "outputs": [],
   "source": [
    "# plot the performance of the two\n",
    "perf = pd.DataFrame({'model':[\"Logistic Regression\", \"Decision Tree\"], \n",
    "                     'auc': [auc_logreg, auc_tree],\n",
    "                     'accuracy': [logreg.score(X_test, y_test), dtree.score(X_test, y_test)]})\n",
    "perf.index = perf['model']\n",
    "perf.plot(kind=\"barh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Qwt38reVSTMm"
   },
   "outputs": [],
   "source": [
    "dot_data = tree.export_graphviz(dtree, \n",
    "                                out_file=None, \n",
    "                                feature_names=X.columns,\n",
    "                                filled=True,\n",
    "                                rounded=True,\n",
    "                                class_names=['0-No','1-Disease']) \n",
    "graph = graphviz.Source(dot_data) \n",
    "graph.render(\"Heart Disease\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wOlKSqLTS134"
   },
   "source": [
    "> The file is located in our working directory.  We can download/view the file which we created called Heart Disease.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "z-LtqEAdS1gW"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nS_eBGOwPRu3"
   },
   "source": [
    "## Decision Tree Exercise\n",
    "\n",
    "Using the same California Housing Dataset from the Logistic Regression example above:\n",
    "\n",
    "- Make sure that you are using the original dataset.  You may need to re-read in the dataset set you are working with the original copy\n",
    "- Consider if the variables are appropriate to be included in the model\n",
    "- calculate the accuracy and AUC of the model\n",
    "- determine if the model performed better than guessing (the baseline)\n",
    "- determine if the model performed better than the logistic regression exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xIy12aRTQVQf"
   },
   "outputs": [],
   "source": [
    "# load the data\n",
    "house = pd.read_csv(\"sample_data/california_housing_train.csv\")\n",
    "house['target'] = (house['median_house_value'] >  house['median_house_value'].mean()).astype(\"int\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U3eJLjkWcYdp"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "28-Supervised ML - Classification 2 - Logistic Regression and Decision Trees.ipynb",
   "private_outputs": true,
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
