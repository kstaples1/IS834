{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OUiO9xH8jTom"
   },
   "source": [
    "# Unsupervised Machine Learning - Cluster Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "avYz9tu3JluG"
   },
   "outputs": [],
   "source": [
    "## update the latest seaborn (0.9.0)\n",
    "# !pip install seaborn==0.9.0\n",
    "# !pip install prophet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "u2NphvDnZRrV"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'fbprophet'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-7190e4110bc0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m## date and timeseries forecasting tooling\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mfbprophet\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mProphet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m## machine learning/predictive analytics tools\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'fbprophet'"
     ]
    }
   ],
   "source": [
    "## setup our environment\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "## date and timeseries forecasting tooling\n",
    "import datetime\n",
    "from fbprophet import Prophet\n",
    "\n",
    "## machine learning/predictive analytics tools             \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier           \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LinearRegression \n",
    "from sklearn.tree import DecisionTreeRegressor \n",
    "from sklearn import metrics\n",
    "import graphviz \n",
    "from sklearn import tree\n",
    "from sklearn.preprocessing import StandardScaler    # <------------ New Imports start here\n",
    "from sklearn.cluster import KMeans  \n",
    "from scipy.cluster.hierarchy import linkage, dendrogram\n",
    "from scipy.cluster.hierarchy import fcluster\n",
    "\n",
    "# a new matplotlib feature\n",
    "from mpl_toolkits import mplot3d\n",
    "\n",
    "\n",
    "## pandas print columns/rows option (100)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "## set the styling for seaborn (white)\n",
    "sns.set_style(\"white\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4DxGyIch1RPQ"
   },
   "source": [
    "# Cluster Analysis in Python\n",
    "\n",
    "\n",
    "\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/c/c8/Cluster-2.svg/1200px-Cluster-2.svg.png\"  height=\"300\" width=\"420\">\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yLxHQNxcW5IZ"
   },
   "source": [
    "### What it is:\n",
    "\n",
    "- Cluster analysis allows us to find patterns in our dataset when we do not have (or want to use) labels for our data of interest.  \n",
    "\n",
    "- We do this by creating groups of, hopefully, similar records based on the values in the __numeric__ columns that we use.\n",
    "\n",
    "### What it does:\n",
    "\n",
    "There are multiple algorithms, but they all basically attempt to:\n",
    "\n",
    "* group similar records together.  Statistically similarity is based on the values in the columns that we feed to the algorithm.  \n",
    "* Records are statistically similar if their __computed distance__ is small\n",
    "* Put the rows in our dataset into groups that group similar records.  \n",
    "\n",
    "While it may not be intuitive, we do this by:\n",
    "\n",
    "- Maximize the similarity of the records a given record is grouped with\n",
    "- Maxmize the **dis**simmilarity between the other clusters (groups) of records\n",
    "\n",
    "###  The output:\n",
    "\n",
    "- a numeric, categorical value (1, 2, 3) that identifies the cluster a record is part of\n",
    "\n",
    "### What it means:\n",
    "\n",
    "These statistically similar groups of records can be used for:\n",
    "\n",
    "- Create customer personas\n",
    "- add a new column in our dataset that can be in Supervised Learning techniques\n",
    "- Profile the groups to see if attributes of interest are more/less likely to occur in the cluster/group\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cM-TDp6mW6-3"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler    \n",
    "from sklearn.cluster import KMeans  \n",
    "from scipy.cluster.hierarchy import linkage, dendrogram\n",
    "from scipy.cluster.hierarchy import fcluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-tcY5LROcaPv"
   },
   "source": [
    "#### What did we do?\n",
    "\n",
    "1. we added a module that can help us adjust our values in a pandas dataframe by creating a [z-score](https://www.statisticshowto.datasciencecentral.com/probability-and-statistics/z-score/) for each column we supply\n",
    "\n",
    "1. imported K-means clustering, an approach where we manually specifiy the number of clusters we want to produce.\n",
    "\n",
    "1.  we are using a new scientific programming package, `scipy`, and are bringing in two functions that allow us to do [hierarchical clustering](https://en.wikipedia.org/wiki/Hierarchical_clustering)\n",
    "\n",
    "1. lastly are adding a function that will allow us to create the clusters after viewing the dendrogram based on the hierarchical clusltering we imported above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hIsYJ67yc2fR"
   },
   "source": [
    "# K-Means Clustering\n",
    "\n",
    "![](https://cdn-images-1.medium.com/max/1600/1*tWaaZX75oumVwBMcKN-eHA.png)\n",
    "\n",
    "### Inputs\n",
    "\n",
    "- the `dataframe` of our __numeric__ inputs that will be used to determine __similiarity__\n",
    "\n",
    "- the `#` of clusters we want, commonly referred to as `k`\n",
    "\n",
    "### Outputs\n",
    "\n",
    "- a numeric value of `k` for each row in our dataframe.   The value represents the grouping, or cluster, value.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TUe8NsFY6IEo"
   },
   "outputs": [],
   "source": [
    "# bring in our dataset\n",
    "med_raw = pd.read_csv(\"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/MedGPA.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eDMhKh-f6kIQ"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Accept</th>\n",
       "      <th>Acceptance</th>\n",
       "      <th>Sex</th>\n",
       "      <th>BCPM</th>\n",
       "      <th>GPA</th>\n",
       "      <th>VR</th>\n",
       "      <th>PS</th>\n",
       "      <th>WS</th>\n",
       "      <th>BS</th>\n",
       "      <th>MCAT</th>\n",
       "      <th>Apps</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>D</td>\n",
       "      <td>0</td>\n",
       "      <td>F</td>\n",
       "      <td>3.59</td>\n",
       "      <td>3.62</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9</td>\n",
       "      <td>38</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "      <td>3.75</td>\n",
       "      <td>3.84</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>8.0</td>\n",
       "      <td>12</td>\n",
       "      <td>45</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>F</td>\n",
       "      <td>3.24</td>\n",
       "      <td>3.23</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9</td>\n",
       "      <td>33</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>F</td>\n",
       "      <td>3.74</td>\n",
       "      <td>3.69</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10</td>\n",
       "      <td>40</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>F</td>\n",
       "      <td>3.53</td>\n",
       "      <td>3.38</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>4.0</td>\n",
       "      <td>11</td>\n",
       "      <td>35</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 Accept  Acceptance Sex  BCPM   GPA  VR  PS   WS  BS  MCAT  Apps\n",
       "0           1      D           0   F  3.59  3.62  11   9  9.0   9    38     5\n",
       "1           2      A           1   M  3.75  3.84  12  13  8.0  12    45     3\n",
       "2           3      A           1   F  3.24  3.23   9  10  5.0   9    33    19\n",
       "3           4      A           1   F  3.74  3.69  12  11  7.0  10    40     5\n",
       "4           5      A           1   F  3.53  3.38   9  11  4.0  11    35    11"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "med_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ec-CUiRM7Ohj"
   },
   "outputs": [],
   "source": [
    "sns.heatmap(med_raw.corr(), cmap=\"Blues\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "b1X_8EV66lSH"
   },
   "outputs": [],
   "source": [
    "sns.scatterplot(x=\"GPA\", y=\"BS\", data=med_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cOC9qwVB7IeV"
   },
   "source": [
    "In a 2D context, where would you draw the line(s) to separate the dataset in half, with higher scores more likely to be admitted to medical school?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "e-0hq9Mk893r"
   },
   "outputs": [],
   "source": [
    "# keep just the two columns above\n",
    "med = med_raw.loc[:, [\"GPA\", \"BS\"]]\n",
    "med.head(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HIsyDeWh_TQR"
   },
   "outputs": [],
   "source": [
    "# create a 2K cluster\n",
    "kmeans = KMeans(n_clusters=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VH24sBhD9-W7"
   },
   "outputs": [],
   "source": [
    "# fit the model\n",
    "kmeans.fit(med)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gTRBunhR_sts"
   },
   "outputs": [],
   "source": [
    "# get the cluster labels\n",
    "med_k = kmeans.predict(med)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "V-Hn9kzB_xws"
   },
   "outputs": [],
   "source": [
    "# what do we have?\n",
    "type(med_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "opWuevKM_10D"
   },
   "outputs": [],
   "source": [
    "# first few values of the array\n",
    "med_k[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gV1LRGl-_43z"
   },
   "outputs": [],
   "source": [
    "# put the cluster label onto the original dataset\n",
    "med_raw['c2'] = med_k\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NC7dEZTVKKw5"
   },
   "outputs": [],
   "source": [
    "med_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Urqew1VMANZR"
   },
   "outputs": [],
   "source": [
    "# plot the scatterplot - but hue by cluster\n",
    "sns.scatterplot(x=\"GPA\", y=\"BS\", data=med_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hPSR3SVsAYmv"
   },
   "outputs": [],
   "source": [
    "# plot the scatterplot - but hue by cluster\n",
    "sns.scatterplot(x=\"GPA\", y=\"BS\", data=med_raw, hue=\"c2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mGUzXcP1KChv"
   },
   "outputs": [],
   "source": [
    "# plot the scatterplot - but hue by cluster\n",
    "plt.figure(figsize=(8,8))\n",
    "sns.scatterplot(x=\"GPA\", y=\"BS\", data=med_raw, hue=\"c2\", style=\"Acceptance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8txvSicZKF4b"
   },
   "outputs": [],
   "source": [
    "# lets look at the agreement\n",
    "pd.crosstab(med_raw['c2'], med_raw['Acceptance'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TUT7BTi8fvIl"
   },
   "outputs": [],
   "source": [
    "# do by percentage of columns going down - how well did the clusters segment the acceptance just using two columns\n",
    "pd.crosstab(med_raw['c2'], med_raw['Acceptance'], normalize='columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tInEgF1ohcAY"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "w-CiK9EIhe2_"
   },
   "source": [
    "# Cluster Quality - Inertia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JFCmAbKKhWBP"
   },
   "source": [
    "![](http://rnowling.github.io/images/bps-multinomial-segmentation/pmf_kmeans_inertia.png)\n",
    "\n",
    "We want to:\n",
    "\n",
    "- minimize inertia\n",
    "- but also minimize the number of clusters (too many to manage, and potentially overfitting)\n",
    "- look for the \"elbow\" as a rule-of-thumb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Kl5b3ZwegZhf"
   },
   "outputs": [],
   "source": [
    "# the silhoutte score for the clustering - inside scikit learn metrics\n",
    "# the process is above is done and averaged for all points\n",
    "# we feed in the dataset used for clustering, and the cluster labels we got back\n",
    "kmeans.inertia_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jRGtfGQsjuhA"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RMBZ7nMiiMIp"
   },
   "outputs": [],
   "source": [
    "# lets use all of the numeric data (not just two points) and generate two clusters\n",
    "med2 = pd.read_csv(\"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/MedGPA.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eSodr_xejsjw"
   },
   "outputs": [],
   "source": [
    "# drop all missing data\n",
    "med2.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OSpSiXWwicrN"
   },
   "outputs": [],
   "source": [
    "# keep just the numeric variables\n",
    "med_numeric = med2.loc[:, \"BCPM\":\"Apps\"]\n",
    "med_numeric.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kt25nwtXinra"
   },
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=2)   # setup cluster algorithm for 2 clusters\n",
    "kmeans.fit(med_numeric)          # fit the model\n",
    "k2 = kmeans.predict(med_numeric)   # generate cluster labels\n",
    "med2['k2'] = k2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CJeBC86-jS1f"
   },
   "outputs": [],
   "source": [
    "# how did our original plot change\n",
    "sns.scatterplot(x=\"GPA\", y=\"BS\", data=med2, hue=\"k2\", style=\"Acceptance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-SRLAsPnj-i7"
   },
   "outputs": [],
   "source": [
    "# interia score  -- did we do better or worse?\n",
    "kmeans.inertia_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dK475lzfhHR-"
   },
   "source": [
    "----\n",
    "\n",
    "\n",
    "Above we learned a few things:\n",
    "\n",
    "1.Clustering is an unsupervised technique, but that doesnt mean our dataset can't have a variable/feature of interest.  We just ignore it and do not include it in our clustering, which allows us to profile by it later\n",
    "\n",
    "2. The features we use in the clustering matter\n",
    "\n",
    "3.  We are setting the value of `k`, but are other combinations of `k` better?\n",
    "\n",
    "We can use our friend the `for` loop to evaluate:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BCdxKypKxQZ1"
   },
   "source": [
    "# Exercise 1:  Use a for loop to test your number of clusters\n",
    "\n",
    "Hints:\n",
    "\n",
    "- empty list and append values\n",
    "- define a range of k\n",
    "- save out the intertia values after the data are fit\n",
    "- review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dU1b4xuWjwG_"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xXiv1Doan62Y"
   },
   "source": [
    "--- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6UGk6RF8xwyA"
   },
   "source": [
    "# Standardize Values\n",
    "\n",
    "When we use features/columns that are on based on different units, those values with the larger variance get more weight.  We can standardize the values to keep everything on the same footing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bOAUz4Unx6wA"
   },
   "outputs": [],
   "source": [
    "# setup the scalter\n",
    "scaler = StandardScaler() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wKUQy4e0yGbP"
   },
   "outputs": [],
   "source": [
    "# fit the scalter to normalize our dataset\n",
    "scaler.fit(med_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9zHcc7May1Fl"
   },
   "outputs": [],
   "source": [
    "# transform the data\n",
    "med_scaled = scaler.transform(med_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rH7rdELUy5bs"
   },
   "outputs": [],
   "source": [
    "med_numeric.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AIt1TNCky7jj"
   },
   "outputs": [],
   "source": [
    "type(med_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d_ctb91_zF9L"
   },
   "outputs": [],
   "source": [
    "med_scaled[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "naiiVdIozF63"
   },
   "outputs": [],
   "source": [
    "# put back into a dataframe\n",
    "med_scaled_df = pd.DataFrame(med_scaled, columns=med_numeric.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_wVSh1w-zF4n"
   },
   "outputs": [],
   "source": [
    "med_scaled_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NWXlLx8OzF2d"
   },
   "outputs": [],
   "source": [
    "# describe\n",
    "med_scaled_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QJzZ6EKQzFvO"
   },
   "outputs": [],
   "source": [
    "# fit a kmeans to the dataset\n",
    "model = KMeans(n_clusters=2)\n",
    "model.fit(med_scaled_df)\n",
    "k2 = model.predict(med_scaled_df)\n",
    "\n",
    "# how did we do?\n",
    "model.inertia_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WD3r5qgfzrFO"
   },
   "outputs": [],
   "source": [
    "# a plot\n",
    "med2['k2_scaled'] = k2\n",
    "sns.scatterplot(x=\"GPA\", y=\"BS\", data=med2, hue=\"k2_scaled\", style=\"Acceptance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eUPCWWcXz7U8"
   },
   "outputs": [],
   "source": [
    "# profile based on a known outcome which you would think cluster the data\n",
    "pd.crosstab(med2['k2_scaled'], med2['Acceptance'], normalize='columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ch8iZmeWkE3p"
   },
   "source": [
    "Check out a number of clusters, now with scaled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nIAe0_zViKVZ"
   },
   "outputs": [],
   "source": [
    "# create an empty list to hold our interia scores\n",
    "i_scores = []\n",
    "\n",
    "# create a range of k values to check - 2 to 15 clusters\n",
    "ks = range(2, 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tqnl45h0lTJ6"
   },
   "outputs": [],
   "source": [
    "# for each k, fit a kmeans cluster model and save the inertia score\n",
    "for k in ks:\n",
    "  kmean = KMeans(n_clusters = k)\n",
    "  kmeans.fit(med_scaled_df)          # fit the model\n",
    "  k_labels = kmeans.predict(med_scaled_df)   # generate the cluster labels\n",
    "  i_scores.append(kmeans.inertia_)    # append the silhoutte score to the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "V72fkLmplyr3"
   },
   "outputs": [],
   "source": [
    "# plot the data\n",
    "silo_df = pd.DataFrame({'k':ks, 'score':i_scores}, index=ks)\n",
    "sns.pointplot(x=\"k\", y=\"score\", data=silo_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "F_k5BI5D0V5W"
   },
   "source": [
    "What would we choose above, and what do we think is happening?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AixOsDdt0gCX"
   },
   "source": [
    "---\n",
    "\n",
    "# Exercise 2:  Cluster the diamonds\n",
    "\n",
    "\n",
    "Using the diamonds dataset found here:\n",
    "\n",
    "`https://vincentarelbundock.github.io/Rdatasets/csv/ggplot2/diamonds.csv`\n",
    "\n",
    "Select the appropriate variables, standardize the dataset, and determine the number of clusters.\n",
    "\n",
    "Hints:\n",
    "\n",
    "- The clustering technique is intensive on _larger_ datasets, so be patient if you are trying to work through varying numbers of `k`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "stB4fMnA2juf"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DSj8qMSv4Zxu"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "imnFJEfA4XRL"
   },
   "source": [
    "----\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "x6789JrR4ZMA"
   },
   "source": [
    "# Hierarchical Clustering\n",
    "\n",
    "\n",
    "![](https://www.displayr.com/wp-content/uploads/2018/03/Screen-Shot-2018-03-28-at-11.48.48-am.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QBCzbSRf41St"
   },
   "outputs": [],
   "source": [
    "cars = pd.read_csv(\"https://vincentarelbundock.github.io/Rdatasets/csv/datasets/mtcars.csv\", index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X0eC-D2c9L_d"
   },
   "outputs": [],
   "source": [
    "cars.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dbe_PSyv9n7-"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ujr64tRS9o1V"
   },
   "outputs": [],
   "source": [
    "# isolate just the numeric and standardize\n",
    "cars_scaler = StandardScaler()\n",
    "cars_scaler.fit(cars)\n",
    "cars_scaled = cars_scaler.transform(cars)\n",
    "cars_df = pd.DataFrame(cars_scaled, columns=cars.columns)\n",
    "cars_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "J_84LCcrSzVW"
   },
   "outputs": [],
   "source": [
    "car_hclust = linkage(cars_df, method=\"complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z6UM-q2oToP2"
   },
   "outputs": [],
   "source": [
    "# plot the data\n",
    "dendrogram(car_hclust,\n",
    "           leaf_rotation=90,\n",
    "           leaf_font_size=6)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "19HtpbPjT1zD"
   },
   "outputs": [],
   "source": [
    "# the labels for the cluster\n",
    "dendrogram(car_hclust,\n",
    "           labels = cars.index,\n",
    "           leaf_rotation=90,\n",
    "           leaf_font_size=10)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "g6E4i-vNT3j7"
   },
   "outputs": [],
   "source": [
    "# you can also play around with the orientation\n",
    "dendrogram(car_hclust,\n",
    "           labels = cars.index,\n",
    "           orientation = \"left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OhUgPhsSWPw_"
   },
   "source": [
    "Ok, now we can extract the clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HLbwEgX-b93h"
   },
   "outputs": [],
   "source": [
    "from scipy.cluster.hierarchy import fcluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hx5CbTMGb-sa"
   },
   "source": [
    "We imported this at the top of the notebook, but the import snippet above gives us `fcluster`, which we can use to extract the clusters that we want.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KfIoD0sLcHUv"
   },
   "outputs": [],
   "source": [
    "# cuts the clusters at the distance shown on the dendrogram, the second argument is that distance\n",
    "clusters = fcluster(car_hclust, 4, criterion='distance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "q3pOAZ2FcYJ1"
   },
   "outputs": [],
   "source": [
    "clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8SifEdWecZPV"
   },
   "outputs": [],
   "source": [
    "# put these back onto the original dataframe\n",
    "cars['hc_clust'] = clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BZdf-6vScfTs"
   },
   "outputs": [],
   "source": [
    "# how many are in each cluster?\n",
    "cars.hc_clust.value_counts(sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NXOni-k6cm5y"
   },
   "outputs": [],
   "source": [
    "# view the data\n",
    "cars.sort_values(\"hc_clust\").head(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OfihZ5FQc6Xq"
   },
   "outputs": [],
   "source": [
    "# finally, profile the clusters using describe and Transpose\n",
    "# cars.groupby(\"hc_clust\").describe().T\n",
    "cars.groupby(\"hc_clust\").mean().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "b30R3fOZdGJQ"
   },
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2hc-56DedhXN"
   },
   "source": [
    "# Exercise 3:  Hierarchical Clustering of 2008 Elections by State\n",
    "\n",
    "For the dataset below:\n",
    "\n",
    "`https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/Election08.csv`\n",
    "\n",
    "- Cluster the states\n",
    "\n",
    "- generate a dendrogram\n",
    "\n",
    "- determine the number of clusters, \n",
    "\n",
    "- and profile if Obama won based on the clusters, which should not be a feature included in the clustering\n",
    "\n",
    "\n",
    "Documentation on the dataset can be found here:\n",
    "\n",
    "https://vincentarelbundock.github.io/Rdatasets/doc/Stat2Data/Election08.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CjWtKmr8jMds"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Pv4pN-scjMK7"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fFANvj18myOj"
   },
   "source": [
    "# Plotting and Other Linkage Methods for Hierarchical Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZQ6B2zbiksmD"
   },
   "outputs": [],
   "source": [
    "# Seaborn also can visualize clusters -- it does a lot of above under the hood\n",
    "election = pd.read_csv(\"https://vincentarelbundock.github.io/Rdatasets/csv/Stat2Data/Election08.csv\", index_col=2)\n",
    "election2 = election.loc[:, \"Income\":\"Dem.Rep\"]\n",
    "election2.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YNs-tI80l9et"
   },
   "outputs": [],
   "source": [
    "# seaborn will cluster rows/columns, = standardizing each column with a z_score (0 for rows, 1 for columns)\n",
    "sns.clustermap(election2, z_score=1, cmap=\"viridis\", metric=\"euclidean\", method=\"complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FR2_Pr8hkSyT"
   },
   "source": [
    "There are other linkage methods that we can try.  These are determining how to group the rows based on similarity or dissimilarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Puc0cTHljL5X"
   },
   "outputs": [],
   "source": [
    "# for the election data, try 4 different methods\n",
    "link_single = linkage(election2, method=\"single\")\n",
    "link_complete = linkage(election2, method=\"average\")\n",
    "link_average = linkage(election2, method=\"average\")\n",
    "link_ward = linkage(election2, method=\"ward\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Q2pUii1PnjPz"
   },
   "outputs": [],
   "source": [
    "# create a 2x2 plot -- starts at 1, not zero, for the third number\n",
    "# https://jakevdp.github.io/PythonDataScienceHandbook/04.08-multiple-subplots.html\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.title(\"Single Linkage\")\n",
    "dendrogram(link_single,\n",
    "           labels = election2.index,\n",
    "           leaf_rotation=90,\n",
    "           leaf_font_size=10)\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.title(\"Complete Linkage\")\n",
    "dendrogram(link_complete,\n",
    "           labels = election2.index,\n",
    "           leaf_rotation=90,\n",
    "           leaf_font_size=10)\n",
    "\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.title(\"Average Linkage\")\n",
    "dendrogram(link_average,\n",
    "           labels = election2.index,\n",
    "           leaf_rotation=90,\n",
    "           leaf_font_size=10)\n",
    "\n",
    "plt.subplot(2, 2, 4)\n",
    "plt.title(\"Ward Linkage\")\n",
    "dendrogram(link_ward,\n",
    "           labels = election2.index,\n",
    "           leaf_rotation=90,\n",
    "           leaf_font_size=10)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zOHOhLOOnzp4"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8NL2iUbwp28V"
   },
   "source": [
    "# Exercise 4:  Avacado Prices\n",
    "\n",
    "Your consulting firm has been asked by Hass avacado to generate a market segmentation strategy based on their weekly sales data by region.\n",
    "\n",
    "The dataset can be found below:\n",
    "\n",
    "`https://raw.githubusercontent.com/Btibert3/is834/master/datasets/avocado.csv`\n",
    "\n",
    "You will need to aggregate the data (ultimately one row per region) and cluster the markets.  You should use both clustering techniques above and profile the final cluster solution.\n",
    "\n",
    "Information on the dataset can be found on Kaggle below:\n",
    "\n",
    "https://www.kaggle.com/neuromusic/avocado-prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vXmPDo0o1QLY"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "30 - Unsupervised Learning.ipynb",
   "private_outputs": true,
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
