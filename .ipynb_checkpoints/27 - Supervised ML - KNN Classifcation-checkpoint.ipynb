{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LA4mNlo5P0aI"
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IL9tlCqIOcvX"
   },
   "outputs": [],
   "source": [
    "## update the latest seaborn (0.9.0) and prophet\n",
    "!pip install seaborn==0.9.0\n",
    "!pip install prophet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cipePZS5Nlys"
   },
   "outputs": [],
   "source": [
    "## setup our environment\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "## date and timeseries forecasting tooling\n",
    "import datetime\n",
    "from fbprophet import Prophet\n",
    "\n",
    "## machine learning/predictive analytics tools              # <-------- New imports!\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "\n",
    "## pandas print columns/rows option (100)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "## set the styling for seaborn (white)\n",
    "sns.set_style(\"dark\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GT0xLRE-Pyt4"
   },
   "source": [
    "# Machine Learning Introduction \n",
    "\n",
    "![](https://i0.wp.com/dataaspirant.com/wp-content/uploads/2014/09/Classification-and-Regression-dataaspirant.png?resize=690%2C518)\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "Machine Learning / Predictive Analytics / Data Mining\n",
    "\n",
    "- process of using data to build models and find patterns in the data\n",
    "\n",
    "\n",
    "In the course to date, we have covered the tools and skills needed to:\n",
    "- acquire data\n",
    "- clean data\n",
    "- sort/filter data (both rows and columns)\n",
    "- get quick summaries of our data\n",
    "- create aggregates of our data\n",
    "- reshape our data\n",
    "- merge datasets\n",
    "- visualize our data\n",
    "\n",
    "From here, the next step of analyzing data is to start to draw insights to make predictions to help with decision making, or find patterns in the data to help simplify operational goals (market segmentation, cluster customers, etc.)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yOa4NBrpRWsJ"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "![](https://www.mathworks.com/help/stats/machinelearning_supervisedunsupervised.png)\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "<br>\n",
    "\n",
    "\n",
    "To view the difference between classification and regression:\n",
    "\n",
    "![](https://cdn-images-1.medium.com/max/1600/0*WE3Sz--1NUEWBmUR.)\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "<br>\n",
    "\n",
    "![](https://blogs.nvidia.com/wp-content/uploads/2018/07/Supervised_machine_learning_in_a_nutshell.svg_.png)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QL6n2a6lSQYo"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QOn3Hu23P5jZ"
   },
   "source": [
    "![](https://upload.wikimedia.org/wikipedia/commons/thumb/0/05/Scikit_learn_logo_small.svg/1200px-Scikit_learn_logo_small.svg.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TZkJG1TGSrmo"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QXaILPMNSPp2"
   },
   "source": [
    "We are going to cover KNN Classification, which uses a value `K` to set the n nearest-neighbors, and from there, take the most frequent value for our target as the prediction.\n",
    "\n",
    "<img src=\"https://monosnap.com/image/oxafG5iNgWtqSAvLE8VFGVR6IVKt6O.png\">\n",
    "\n",
    "\n",
    "\n",
    "#### Terminology:\n",
    "\n",
    "- `K`:  how many nearest neighbors to use to drive the consensus prediction\n",
    "- `features`:  these are the variables that we use to drive the predictions\n",
    "- `target, or y`:  the variable that we are trying to predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Q7FJLgmYUAXm"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yN1CxoUngfuH"
   },
   "source": [
    "![](http://seekvectorlogo.com/wp-content/uploads/2018/01/spotify-vector-logo-small.png)\n",
    "\n",
    "We have been hired by Spotify to figure out if we can classify the `mode` of new songs hitting their music platform based on the musical properties of the track.  We can use K-Nearest Neighbors Classification to learn the target variable using the top 100 songs from last year.\n",
    "\n",
    "\n",
    "\n",
    "<br>\n",
    "<brr>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rl1xuAxdTe2A"
   },
   "outputs": [],
   "source": [
    "## load our dataset\n",
    "url = \"https://raw.githubusercontent.com/Btibert3/is834/master/datasets/top100-songs-2018.csv\"\n",
    "songs = pd.read_csv(url)\n",
    "songs.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qQS5s5FaUqx2"
   },
   "outputs": [],
   "source": [
    "## confirm we have missing values -- express as percentage\n",
    "songs.isna().sum() / len(songs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wzMBSJucUyv-"
   },
   "source": [
    "Most machine learning techniques, especially when we write code, get angry when we:\n",
    "\n",
    "- have missing values\n",
    "- are data are not numeric in nature\n",
    "\n",
    "In particular, scikit learn requires that our data are numeric and either represent numpy arrays or pandas dataframes.  We will see that in a moment.\n",
    "\n",
    "For now, lets clean the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sw0tznZgVJzV"
   },
   "outputs": [],
   "source": [
    "# remove the column with majority nas\n",
    "songs.drop(columns=[\"instrumentalness\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tKcbM6FDV_LN"
   },
   "outputs": [],
   "source": [
    "# replace the other missing values with the mean from each column\n",
    "dance_mean = songs.danceability.mean()\n",
    "songs.danceability.fillna(dance_mean, inplace=True)\n",
    "live_mean = songs.liveness.mean()\n",
    "songs.liveness.fillna(live_mean, inplace=True)\n",
    "energy_mean = songs.energy.mean()\n",
    "songs.energy.fillna(energy_mean, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VD2LsBrcW6D-"
   },
   "outputs": [],
   "source": [
    "# confirm\n",
    "songs.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9wPOnHvNWe5c"
   },
   "outputs": [],
   "source": [
    "# Because we are trying to predict a value, we need to think about the columns we want to use as features, and then the target\n",
    "songs['mode'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vylC2O8UXJVG"
   },
   "source": [
    "> We will use the mode column as our target variable, as its binary to keep things simple, also numeric, and relatively balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iz0XLT3eXdwc"
   },
   "outputs": [],
   "source": [
    "# list the columns\n",
    "songs.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o0xoZXlxXpMY"
   },
   "outputs": [],
   "source": [
    "songs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qOqT0f1XWg3V"
   },
   "outputs": [],
   "source": [
    "# keep the columns that we want as features (those that we will use to find nearest neighbors\n",
    "song_features = songs.loc[:, \"danceability\":\"time_signature\"]  ## we can slice here too = select column range\n",
    "song_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IKwOINxIWn0l"
   },
   "outputs": [],
   "source": [
    "# keep the mode column as our target, and then drop it from the features so it is not redundant\n",
    "song_target = song_features.loc[:, \"mode\"]\n",
    "song_features.drop(columns=[\"mode\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rJmMIB6EYHgq"
   },
   "outputs": [],
   "source": [
    "# confirm things look good\n",
    "print(song_features.shape)\n",
    "print(song_target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ewUMkAcxYP4-"
   },
   "outputs": [],
   "source": [
    "# and double confirm the types\n",
    "print(song_features.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "93hs4WPAYcOa"
   },
   "outputs": [],
   "source": [
    "song_target.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "I8JYusiHYii5"
   },
   "source": [
    "# Fit our First Model\n",
    "\n",
    "\n",
    "We are now ready to fit our first model, and we will see over the next few weeks that the syntax is pretty consistent no matter the task we want to perform, just like seaborn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jd-cdOnsYzfH"
   },
   "outputs": [],
   "source": [
    "# setup the model with the parameters we want to include for fitting\n",
    "knn = KNeighborsClassifier(n_neighbors=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R4V58C45ZFor"
   },
   "outputs": [],
   "source": [
    "# use the fit method to add our features, and then target\n",
    "knn.fit(song_features, song_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3x81tK1_ZR3G"
   },
   "source": [
    "> Above scikit learn and the KNN method is telling us the parameters we are using, even though we only specififed how many neighbors we wanted to include"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9vAl1f5FZYzq"
   },
   "outputs": [],
   "source": [
    "# now that the model has been fit to the data, we want to make predictions\n",
    "song_preds = knn.predict(song_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ab-RAgrPZrUE"
   },
   "outputs": [],
   "source": [
    "# lets look at the predictions -- use our original data that we fit the model to\n",
    "# this is not great, but will come back to this\n",
    "type(song_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "12QiDLw6ZtOb"
   },
   "outputs": [],
   "source": [
    "song_preds[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-AVuqzSaZy45"
   },
   "outputs": [],
   "source": [
    "# how does that compare to our known values in song_target\n",
    "# type(song_target)\n",
    "song_target[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eDmHwmKwdKGz"
   },
   "source": [
    "---\n",
    "\n",
    "# Fit our Second Model - But Assess Accuracy Properly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "w_KUWLEYZ9oT"
   },
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "![](https://d2h0cx97tjks2p.cloudfront.net/blogs/wp-content/uploads/sites/2/2018/08/1-16.png)\n",
    "\n",
    "<br>\n",
    "\n",
    "When fitting models, we always want to split our data so that we can test the accuracy of the model.  The model will always perform best on the data used to train it, so in practice, we need to test on a new set of data.\n",
    "\n",
    "This is called training/test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zRLxUnF-aPi_"
   },
   "outputs": [],
   "source": [
    "# use the normal convention, and spit out the training and test bits for the features (X) and target (y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(song_features, song_target, test_size = .25, random_state=33, stratify=song_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "T_dbKdezbFwa"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "** Wait, what did we just do?**\n",
    "\n",
    "- train_test_split generates 4 sets of data (train and test datasets for the features and the target variable)\n",
    "- we set the test size to be 25% of the total records\n",
    "- random_state is a random number to help with reproducibilty locally\n",
    "- stratify allows us to respect the distribution the best we can of the target variable the best we can\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TkeZY6d5bgsT"
   },
   "outputs": [],
   "source": [
    "help(train_test_split)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Pez2bdzFcBER"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BwQ14n0_bazb"
   },
   "outputs": [],
   "source": [
    "# fit the model again, but leverage the bits that we have for a better assessment of accuracy\n",
    "knn2 = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "# fit the model with the training data\n",
    "knn2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JSq-mVBKcPmT"
   },
   "outputs": [],
   "source": [
    "# now instead of making predictions on the data, we will score the dataset on accuracy using the test features and known values \n",
    "knn2.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MmFs8iJrcZ9u"
   },
   "source": [
    "> Above, we are applying a simple accuracy metric.  We still know the labels in the test dataset, so we are comparing the predictions to the known value for `mode`, and the value above shows the % agreement, or how \"accurate\" we were and predicting the mode."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "f3Vvvh5Zc7gY"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "# How about different values of K?\n",
    "\n",
    "Just like last week when we went through how to look at moving averages, and how many values to include is subjective and worth testing, we can test various values of K.\n",
    "\n",
    "And we can do this using the skills we learned at the begginning of class!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qlEF7kOUdY0s"
   },
   "outputs": [],
   "source": [
    "# Since our dataset has 100 rows, and we are going to use 25 for testing, lets do 1 to 11 (we only have 25 test cases)\n",
    "num_nbrs = range(1, 12)\n",
    "print(np.array(num_nbrs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "H1_EwcNndyTb"
   },
   "outputs": [],
   "source": [
    "# setup empty lists to hold our data\n",
    "train_score = []\n",
    "test_score = []\n",
    "\n",
    "# use a for loop to loop over the values of K and assess the accuracy\n",
    "for i in num_nbrs:\n",
    "  # instatiate (setup/configure) the model\n",
    "  knn_model = KNeighborsClassifier(n_neighbors=i)\n",
    "  # fit the model\n",
    "  knn_model.fit(X_train, y_train)\n",
    "  # get the scores\n",
    "  train_score.append(knn_model.score(X_train, y_train))\n",
    "  test_score.append(knn_model.score(X_test, y_test))\n",
    "  # status\n",
    "  print(\"finished record {}\".format(str(i)))\n",
    "                     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MW84bSJ5fM1Y"
   },
   "outputs": [],
   "source": [
    "# put the data into a dataframe and set the index to represent our value of K\n",
    "df_results = pd.DataFrame({'train':train_score, 'test':test_score}, index=num_nbrs)\n",
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9KDB-V9pfcLf"
   },
   "outputs": [],
   "source": [
    "# plot the data\n",
    "df_results.plot(kind=\"line\", figsize=(15, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YMH7TQTsfsY8"
   },
   "source": [
    "## Business Analytics: Interpret the results\n",
    "\n",
    "Discuss the results above, what do we think is going on? \n",
    "\n",
    "What should we use for a value of K?  \n",
    "\n",
    "How accurate are we?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2kc-lfdmgXHx"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "27 - Supervised ML - KNN Classifcation.ipynb",
   "private_outputs": true,
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
